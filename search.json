[
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "Test Data\nWhy does this exist? I like using langgraph. Modeling reasoning processes as graphs makes sense. However, there’s a few problems that make it difficult for me. First of all, I have a terrible memory. I really can’t memorize a constantly changing API, and I get tired looking up stuff I don’t remember. And if I’m thinking of a graph, with nodes and edges, the langgraph architecture is great. I just don’t know all the variations of it off the top of my head. All I know is a sort of state graph like: START -&gt; do_something -&gt; END\nNow I want to code that up in langgraph. What do I need? Exactly how do I code these? It’s not at all clear given a notation like this: START -&gt; node_1 -&gt; node_2 -&gt; END\nThis tool let’s you define graphs this way, and writes functioning langgraph code.\n\n\nExample Graphs in this notation\nThese graphs are taken from the langchain video Building Effective Agents with LangGraph\n\nbea_basic = \"\"\"START -&gt; generate_joke\ngenerate_joke -&gt; check_punchline(improve_joke, END)\nimprove_joke -&gt; polish_joke -&gt; END\n\"\"\"\n\nbea_parallel = \"\"\"START -&gt; call_llm_1, call_llm_2, call_llm_3 -&gt; aggregator -&gt; END\"\"\"\n\nbea_orchestrator_worker = \"\"\"START -&gt; orchestrator -&gt; llm_call(*sections) -&gt; synthesizer -&gt; END\"\"\"\n\n\ntest_cases = {\n    \"bea_basic\": {\n        \"notation\": bea_basic,\n        \"expected\": [\n            ('START', 'generate_joke'),\n            ('generate_joke', 'check_punchline(improve_joke, END)'),\n            ('improve_joke', 'polish_joke'),\n            ('polish_joke', 'END')\n        ]\n    },\n    \"bea_parallel\": {\n        \"notation\": bea_parallel,\n        \"expected\": [\n            ('START', 'call_llm_1'),\n            ('START', 'call_llm_2'),\n            ('START', 'call_llm_3'),\n            ('call_llm_1', 'aggregator'),\n            ('call_llm_2', 'aggregator'),\n            ('call_llm_3', 'aggregator'),\n            ('aggregator', 'END')\n        ]\n    },\n    \"bea_orchestrator_worker\": {\n        \"notation\": bea_orchestrator_worker,\n        \"expected\": [\n            ('START', 'orchestrator'),\n            ('orchestrator', 'llm_call(*sections)'),\n            ('llm_call(*sections)', 'synthesizer'),\n            ('synthesizer', 'END')\n        ]\n    }\n}\n\n\nStep 1: break into pairs\nAll operations after this use: - graph_name – used in code generation - graph_notation – see examples, only 4 patters: simple transition A -&gt; B, parallel destinations A -&gt; B, C, D - graph_data – pairs of related graph entities, where each node transitions to\n\nsource\n\n\n\nget_graph_data\n\n get_graph_data (graph_notation:str)\n\nGiven a text representation of the graph, return pairs of components\n\ngraph_name = \"bea_basic\"\ngraph_notation = bea_basic\ngraph_data = get_graph_data(graph_notation)\ngraph_name, graph_notation, graph_data\n\n('bea_basic',\n 'START -&gt; generate_joke\\ngenerate_joke -&gt; check_punchline(improve_joke, END)\\nimprove_joke -&gt; polish_joke -&gt; END\\n',\n [('START', 'generate_joke'),\n  ('generate_joke', 'check_punchline(improve_joke, END)'),\n  ('improve_joke', 'polish_joke'),\n  ('polish_joke', 'END')])\n\n\n\nassert(test_cases[graph_name]['notation'] == graph_notation)\nassert(test_cases[graph_name]['expected'] == graph_data)\n\n\ngraph_name = \"bea_parallel\"\ngraph_notation = bea_parallel\ngraph_data = get_graph_data(graph_notation)\ngraph_name, graph_notation, graph_data\n\n('bea_parallel',\n 'START -&gt; call_llm_1, call_llm_2, call_llm_3 -&gt; aggregator -&gt; END',\n [('START', 'call_llm_1'),\n  ('START', 'call_llm_2'),\n  ('START', 'call_llm_3'),\n  ('call_llm_1', 'aggregator'),\n  ('call_llm_2', 'aggregator'),\n  ('call_llm_3', 'aggregator'),\n  ('aggregator', 'END')])\n\n\n\nassert(test_cases[graph_name]['notation'] == graph_notation)\nassert(test_cases[graph_name]['expected'] == graph_data)\n\n\ngraph_name = \"bea_orchestrator_worker\"\ngraph_notation = bea_orchestrator_worker\ngraph_data = get_graph_data(graph_notation)\ngraph_name, graph_notation, graph_data\n\n('bea_orchestrator_worker',\n 'START -&gt; orchestrator -&gt; llm_call(*sections) -&gt; synthesizer -&gt; END',\n [('START', 'orchestrator'),\n  ('orchestrator', 'llm_call(*sections)'),\n  ('llm_call(*sections)', 'synthesizer'),\n  ('synthesizer', 'END')])\n\n\n\nassert(test_cases[graph_name]['notation'] == graph_notation)\nassert(test_cases[graph_name]['expected'] == graph_data)",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "lgcodegen2",
    "section": "",
    "text": "Why does this exist? I like using langgraph. Modeling reasoning processes as graphs makes sense. However, there’s a few problems that make it difficult for me. First of all, I have a terrible memory. I really can’t memorize a constantly changing API, and I get tired looking up stuff I don’t remember. And if I’m thinking of a graph, with nodes and edges, the langgraph architecture is great. I just don’t know all the variations of it off the top of my head. All I know is a sort of state graph like: START -&gt; do_something -&gt; END\nNow I want to code that up in langgraph. What do I need? Exactly how do I code these? It’s not at all clear given a notation like this: START -&gt; node_1 -&gt; node_2 -&gt; END\nThis tool let’s you define graphs this way, and writes functioning langgraph code.",
    "crumbs": [
      "lgcodegen2"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "lgcodegen2",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall lgcodegen2 in Development mode\n# make sure lgcodegen2 package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to lgcodegen2\n$ nbdev_prepare",
    "crumbs": [
      "lgcodegen2"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "lgcodegen2",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/jojohannsen/lgcodegen2.git\nor from conda\n$ conda install -c jojohannsen lgcodegen2\nor from pypi\n$ pip install lgcodegen2\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on conda and pypi respectively.",
    "crumbs": [
      "lgcodegen2"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "lgcodegen2",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2\n\n\n\nThe Plan\nWe start with the Graph Notation, and do the following:\n\nbreak graph into edges, just a tuple (“A”, “B”) from notation A -&gt; B\nhandle parallel branching, a tuple (“A”, “B,C,D”) becomes (“A”, “B”), (“A”, C”), (“A”, “D”)\nhandle conditional edges, notation: “condition_fn(node_1, node_2)”\nwrite state code\nwrite node code\nwrite conditional edge code\nwrite worker function code\nwrite graph builder code\nwrite graph runner code",
    "crumbs": [
      "lgcodegen2"
    ]
  }
]